{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import libraries and setup for scrape\n","\n","import GetOldTweets3 as got\n","import pandas as pd\n","import os\n","\n","# Scraping Parameters\n","start_date = \"2020-04-23\"\n","end_date = \"2020-04-26\"\n","max_tweet = 10000\n","group = \"sen\"  # 'sen' or 'rep' (for now)\n","obs = [\n","    \"to\",\n","    \"id\",\n","    \"hashtags\",\n","    \"mentions\",\n","    \"geo\",\n","]  # Parameter for column formatting used later on\n","\n","# Check for existing csv file\n","data_file_list = os.listdir(\"../Data\")\n","filename = group + \".csv\"\n","\n","if (filename) in data_file_list:\n","    base_df = pd.read_csv(\"../Data/\" + filename, parse_dates=[\"date\"])\n","else:\n","    base_df = pd.read_csv(\"../Data/test.csv\", parse_dates=[\"date\"])\n","    base_df = base_df[0:0]\n","\n","# Correct column formats\n","base_df[obs] = base_df[obs].astype(object)\n","\n","# Initialize df to export later\n","new_df = base_df\n","\n","# CSV pulled from https://github.com/unitedstates/congress-legislators (lightly modified to correct some twitter accounts)\n","congress = pd.read_csv(\"../Data/legislators-current.csv\")\n","congress_sub = congress[congress[\"type\"] == group]\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get the scrape on\n","# Can scrape about 1 month of data (~10000 tweets) before getting kicked out by twitter, switch vpn network between runs\n","for index, row in congress_sub.iterrows():\n","    username = row[\"twitter\"]\n","    print(\"Scraping twitter account \" + username + \"...\")\n","\n","    tweetCriteria = (\n","        got.manager.TweetCriteria()\n","        .setUsername(username)\n","        .setSince(start_date)\n","        .setUntil(end_date)\n","        .setMaxTweets(max_tweet)\n","    )\n","\n","    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n","\n","    tweets_df = pd.DataFrame.from_records([t.__dict__ for t in tweets])\n","    new_df = new_df.append(tweets_df, ignore_index=True)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Prepare and export to csv\n","# Delete duplicates\n","new_df[[\"id\"]] = new_df[[\"id\"]].apply(pd.to_numeric)\n","return_df = new_df.drop_duplicates(subset=\"id\")\n","\n","# Export\n","return_df.to_csv(path_or_buf=\"../Data/\" + filename, index=False)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Doublechecks before export (if wanted)\n","counts_scraped = new_df.groupby([\"username\"]).size().to_frame()\n","counts_scraped[\"twitter\"] = counts_scraped.index\n","counts_scraped.columns = [\"count\", \"twitter\"]\n","counts = (\n","    congress_sub[\"twitter\"].to_frame().merge(counts_scraped, how=\"left\", on=\"twitter\")\n",")\n","unique_check = counts.twitter.value_counts()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}